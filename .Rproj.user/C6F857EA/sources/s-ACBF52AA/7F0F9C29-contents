---
title: "Ch1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Environment

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(vioplot)
library(corrplot)
library(gmodels)
library(matrixStats)
library(reticulate)
# conda_install("r-reticulate", "wquantiles") #for python code execution
# conda_install("r-reticulate", "statsmodels") #for python code execution
```

```{python}
from pathlib import Path

import pandas as pd
import numpy as np
from scipy.stats import trim_mean
from statsmodels import robust
import wquantiles

import seaborn as sns
import matplotlib.pylab as plt

try:
    import common
    DATA = common.dataDirectory()
except ImportError:
    DATA = Path().resolve() / 'data'

# Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names.

# AIRLINE_STATS_CSV = DATA / 'airline_stats.csv'
# KC_TAX_CSV = DATA / 'kc_tax.csv.gz'
# LC_LOANS_CSV = DATA / 'lc_loans.csv'
# AIRPORT_DELAYS_CSV = DATA / 'dfw_airline.csv'
# SP500_DATA_CSV = DATA / 'sp500_data.csv.gz'
# SP500_SECTORS_CSV = DATA / 'sp500_sectors.csv'
STATE_CSV = DATA / 'state.csv'
```

## 1.3 Estimates of Location

> p.12

### R

```{r}
PSDS_PATH <- file.path((getwd())) #Adjust the syntax to get the specific file path.
PSDS_PATH 
state <- read.csv(file.path(PSDS_PATH, 'data', 'state.csv'))
state
```

```{r}
state %>% class()
state_asc <- state
#Change the format of numbers, e.g. 10000 -> 10,000
state_asc[['Population']] <- formatC(state_asc[['Population']], format='d', digits=0, big.mark=',') 
state_asc[1:8,]

mean(state[['Population']])
mean(state[['Population']], trim=0.1)
median(state[['Population']])

mean(state[['Murder.Rate']])
weighted.mean(state[['Murder.Rate']], w=state[['Population']])
# library('matrixStats')
weightedMedian(state[['Murder.Rate']], w=state[['Population']])
```

### Py

```{python}
state = pd.read_csv(STATE_CSV)
print(state.head(8))

# Compute the mean, trimmed mean, and median for Population. For `mean` and `median` we can use the _pandas_ methods of the data frame. The trimmed mean requires the `trim_mean` function in _scipy.stats_.

state = pd.read_csv(STATE_CSV)
state.__class__
print(state['Population'].mean())

print(trim_mean(state['Population'], 0.1))

print(state['Population'].median())

# Weighted mean is available with numpy. For weighted median, we can use the specialised package `wquantiles` (https://pypi.org/project/wquantiles/).

print(state['Murder.Rate'].mean())
print(np.average(state['Murder.Rate'], weights=state['Population']))
print(wquantiles.median(state['Murder.Rate'], weights=state['Population']))

```

## 1.4 Estimates of Variability

> p.18

### R

```{r}
# state$Population %>% sd()
sd(state[['Population']])
IQR(state[['Population']])
mad(state[['Population']])
```

### Py

```{python}
print(state.head(8))

# Standard deviation

print(state['Population'].std())

# Interquartile range is calculated as the difference of the 75% and 25% quantile.

print(state['Population'].quantile(0.75) - state['Population'].quantile(0.25))

# Median absolute deviation from the median can be calculated with a method in _statsmodels_
print(state['Population'].mean())
print(state['Population'].median())
print(robust.scale.mad(state['Population']))
# print(abs(state['Population'] - state['Population'].median()).median() / 0.6744897501960817)

```

## 1.5 Exploring the Data Distribution

> p.20

### R

```{r}
quantile(state[['Murder.Rate']], p=c(.05, .25, .5, .75, .95))

boxplot(state[['Population']]/1000000, ylab='Population (millions)')
```

```{r Frequency Tables and Histograms}
breaks <- seq(from=min(state[['Population']]), 
              to=max(state[['Population']]), length=11)
pop_freq <- cut(state[['Population']], breaks=breaks, 
                right=TRUE, include.lowest=TRUE)
state['PopFreq'] <- pop_freq
table(pop_freq)

options(scipen=5)
#integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation. Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than scipen digits wider.
hist(state[['Population']], breaks=breaks)
```

### Py

```{python}
# _Pandas_ has the `quantile` method for data frames.

print(state['Murder.Rate'].quantile([0.05, 0.25, 0.5, 0.75, 0.95]))

# _Pandas_ provides a number of basic exploratory plots; one of them are boxplots

ax = (state['Population']/1_000_000).plot.box(figsize=(3, 4))
ax.set_ylabel('Population (millions)')

plt.tight_layout()
plt.show()
```

```{python Frequency Tables and Histograms}
# The `cut` method for _pandas_ data splits the dataset into bins. There are a number of arguments for the method. The following code creates equal sized bins. The method `value_counts` returns a frequency table.

binnedPopulation = pd.cut(state['Population'], 10) #cut into 10 bins
print(binnedPopulation.value_counts())
```

```{python Frequency Tables and Histograms}
binnedPopulation.name = 'binnedPopulation'
df = pd.concat([state, binnedPopulation], axis=1)
df = df.sort_values(by='Population')
df
groups = []
for group, subset in df.groupby(by='binnedPopulation'):
    groups.append({
        'BinRange': group,
        'Count': len(subset),
        'States': ','.join(subset.Abbreviation)
    })
print(pd.DataFrame(groups))
```

```{python}
# _Pandas_ also supports histograms for exploratory data analysis.
#With DataFrame.plot.hist method.
ax = (state['Population'] / 1_000_000).plot.hist(figsize=(4, 4))
ax.set_xlabel('Population (millions)')
# plt.close("all") #clear out all the graph and reset to an empty white background.
plt.tight_layout()
plt.show()
```


